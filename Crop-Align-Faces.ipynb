{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOHPmGz5be3Vj6bskRKFLUs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PRAN20/Crop-Align-Faces/blob/main/Crop-Align-Faces.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mediapipe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oWawgRg0iiG",
        "outputId": "bf47ec0d-fa3e-4454-abdb-c250f370b825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.8.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 32.8 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from mediapipe) (0.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.15.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (from mediapipe) (4.1.2.30)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from mediapipe) (0.37.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.2.2)\n",
            "Requirement already satisfied: protobuf>=3.11.4 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.17.3)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (21.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (3.0.6)\n",
            "Installing collected packages: mediapipe\n",
            "Successfully installed mediapipe-0.8.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from os import path\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import mediapipe as mp"
      ],
      "metadata": {
        "id": "rxzdAirw080c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EXTRACT THE FILES FROM DRIVE**\n",
        "\n"
      ],
      "metadata": {
        "id": "SPEBR44f1kDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VjWBdux_1sWj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c7f982f-7e92-4682-f2ba-8eaf085e3ffb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RENAME THE DATASETS TO NEW NAME**"
      ],
      "metadata": {
        "id": "b38PfAn83huo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"checK\")\n"
      ],
      "metadata": {
        "id": "DG_L44jT3t6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EXTRACT FILES FROM DATABASE**"
      ],
      "metadata": {
        "id": "e1IBQBY-4L58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \" // LNK \" -d \"check\"\n"
      ],
      "metadata": {
        "id": "R0vJKaRj4rEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DECLARING CLASSES**"
      ],
      "metadata": {
        "id": "Id_chLyg5aEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Face:\n",
        "    area = 0\n",
        "    x = 0\n",
        "    y = 0\n",
        "    width = 0\n",
        "    height = 0\n",
        "    image = None\n",
        "    left_eye = (0, 0)\n",
        "    right_eye = (0, 0)\n"
      ],
      "metadata": {
        "id": "xOz4Yost5qgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FaceTool:\n",
        "    face_cascade = None\n",
        "    eye_cascade = None\n",
        "    debug = False\n",
        "\n",
        "    face_detection = None\n",
        "    face_mesh = None"
      ],
      "metadata": {
        "id": "9f0KUatM54ZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DECLARE INITIAL FUNCTION**"
      ],
      "metadata": {
        "id": "E4iwBfJ26Lgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def __init__(self, debug=False) -> None:\n",
        "  self.debug = debug\n",
        "  mp_face_detection = mp.solutions.face_detection\n",
        "  self.face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.5)\n"
      ],
      "metadata": {
        "id": "cYPcLFjT6wGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DECLARING REGULAR FUNCTIONS**"
      ],
      "metadata": {
        "id": "OmigVzuQ7MSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def imcrop(self, img, bbox):\n",
        "   x2, y2, x1, y1 = np.array(bbox, dtype='int')\n",
        "   if x1 < 0 or y1 < 0 or x2 > img.shape[1] or y2 > img.shape[0]:\n",
        "    img, x1, x2, y1, y2 = self.pad_img_to_fit_bbox(img, x1, x2, y1, y2)\n",
        "  return img[y1:y2, x1:x2, :]\n"
      ],
      "metadata": {
        "id": "39edfR8x7ejM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_img_to_fit_bbox(self, img, x1, x2, y1, y2):\n",
        "  img = cv2.copyMakeBorder(img, - min(0, y1), max(y2 - img.shape[0], 0), -min(0, x1), max(x2 - img.shape[1], 0), cv2.BORDER_REPLICATE)\n",
        "    y2 += -min(0, y1)\n",
        "    y1 += -min(0, y1)\n",
        "    x2 += -min(0, x1)\n",
        "    x1 += -min(0, x1)\n",
        "    return img, x1, x2, y1, y2\n"
      ],
      "metadata": {
        "id": "NmUFGbvL8BwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_and_align(self, image_or_array=None, size=512, offset_x=0, offset_y=10, zoom_factor=2.0):\n",
        "  img = None\n",
        "  if isinstance(image_or_array, str):\n",
        "    if not path.exists(image_or_array):\n",
        "      message = \"FaceTool: Image Path not found\"\n",
        "      return False, None,  message\n",
        "    img = cv2.imread(image_or_array)\n",
        "    elif type(image_or_array) is np.ndarray:\n",
        "      img = image_or_array\n",
        "    else:\n",
        "       message = \"FaceTool: Invalid Image\"\n",
        "       return 0, None, message\n",
        "    #Convert the BGR image to RGB and process it with MediaPipe Face Detection.\n",
        "    face_results = self.face_detection.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    # Defining and drawing the rectangle around the face\n",
        "    if not face_results.detections:\n",
        "      message = \"FaceTool: Face not found\"\n",
        "      return 0, None, message\n",
        "    max_area = 0\n",
        "    faces = []\n",
        "    image_height, image_width = img.shape[:2]\n",
        "    for face_index, face_result in enumerate(face_results.detections):\n",
        "      face = Face()\n",
        "      face.x = int(face_result.location_data.relative_bounding_box.xmin * image_width)\n",
        "      face.y = int(face_result.location_data.relative_bounding_box.ymin * image_height)\n",
        "      face.width = int(face_result.location_data.relative_bounding_box.width * image_width)\n",
        "      face.height = int(face_result.location_data.relative_bounding_box.height * image_height)\n",
        "      face.right_eye = (int(face_result.location_data.relative_keypoints[0].x * image_width), int(face_result.location_data.relative_keypoints[0].y * image_height))face.left_eye = (int(face_result.location_data.relative_keypoints[1].x * image_width), int(face_result.location_data.relative_keypoints[1].y * image_height))\n",
        "      face.area = face.width * face.height\n",
        "      if(face.area > max_area):\n",
        "        max_area = face.area\n",
        "        large_face_index = face_index\n",
        "        if(face.right_eye != None and face.left_eye != None):\n",
        "          left_eye_x = face.left_eye[0]\n",
        "          left_eye_y = face.left_eye[1]\n",
        "          right_eye_x = face.right_eye[0]\n",
        "          right_eye_y = face.right_eye[1]\n",
        "          if self.debug:\n",
        "            cv2.circle(img, face.right_eye, 5, (255, 0, 0), -1)\n",
        "            cv2.circle(img, face.left_eye, 5, (255, 0, 0), -1)\n",
        "            cv2.line(img, face.right_eye, face.left_eye, (0, 200, 200), 3)\n",
        "            if left_eye_y > right_eye_y:\n",
        "              A = (right_eye_x, left_eye_y)\n",
        "            else:\n",
        "              A = (left_eye_x, right_eye_y)\n",
        "              cv2.circle(img, A, 5, (255, 0, 0), -1)\n",
        "              cv2.line(img, face.right_eye,\n",
        "              face.left_eye, (0, 200, 200), 3)\n",
        "              cv2.line(img, face.left_eye, A, (0, 200, 100), 3)\n",
        "              cv2.line(img, face.right_eye, A, (0, 200, 100), 3)\n",
        "              # cv2.imwrite('roi_' + str(face_index) + '.png', img)\n",
        "              # cv2.imshow('image', img)\n",
        "              # cv2.waitKey(0)\n",
        "              delta_x = right_eye_x - left_eye_x\n",
        "              delta_y = right_eye_y - left_eye_y\n",
        "              angle = np.arctan(delta_y/delta_x)\n",
        "              angle = (angle * 180) / np.pi\n",
        "              pointsToTransform = np.float32([[[right_eye_x, right_eye_y], [left_eye_x, left_eye_y], ] ] )\n",
        "              # Calculating a center point of the image\n",
        "              # Integer division \"//\"\" ensures that we receive whole numbers\n",
        "              center = (image_width // 2, image_height // 2)\n",
        "              # Defining a matrix M and calling\n",
        "              # cv2.getRotationMatrix2D method\n",
        "              M = cv2.getRotationMatrix2D(center, (angle), 1.0)\n",
        "              # Applying the rotation to our image using the\n",
        "              # cv2.warpAffine method\n",
        "              rotated = cv2.warpAffine(img, M, (image_width, image_height))\n",
        "              # cv2.imwrite('rotated_' + str(face_index) + '.png', rotated)\n",
        "              # cv2.imshow(\"rotated\",rotated)\n",
        "              # cv2.waitKey(0)\n",
        "              transformedPoints = cv2.transform(pointsToTransform, M)[0]\n",
        "              transformed_right_eye = transformedPoints[0]\n",
        "              transformed_left_eye = transformedPoints[1]\n",
        "              transformed_mid_point_x = int(transformed_left_eye[0] + (transformed_right_eye[0] - transformed_left_eye[0])/2) + int(offset_x)\n",
        "              transformed_mid_point_y = int(transformed_left_eye[1] + (transformed_right_eye[1] - transformed_left_eye[1])/2) + int(offset_y)\n",
        "              padding = int((transformed_right_eye[0] - transformed_left_eye[0]) * zoom_factor)\n",
        "              if self.debug:\n",
        "                cv2.circle(rotated, (transformed_mid_point_x, transformed_mid_point_y), 5, (96, 0, 90), -1) cv2.circle(rotated, tuple(transformed_right_eye), 5, (255, 255, 0), -1)\n",
        "                cv2.circle(rotated, tuple(transformed_left_eye), 5, (255, 150, 0), -1)\n",
        "                cv2.rectangle(rotated, (transformed_mid_point_x - padding, transformed_mid_point_y - padding), (transformed_mid_point_x + padding, transformed_mid_point_y + padding), (0, 255, 0), 3)\n",
        "                aligned = self.imcrop(rotated, [transformed_mid_point_x - padding,transformed_mid_point_y - padding, transformed_mid_point_x + padding,transformed_mid_point_y + padding,])\n",
        "                # cv2.imwrite('aligned_' + str(face_index) + '.png', rotated)\n",
        "              else:\n",
        "                padding = face.width//2.5 * zoom_factor\n",
        "                midpoint_x = face.x + face.width//2\n",
        "                midpoint_y = face.y + face.height//2\n",
        "                aligned = self.imcrop(img, [midpoint_x - padding, midpoint_y - padding, midpoint_x + padding, midpoint_y + padding, ])\n",
        "              if(aligned.shape[0] <= 0 or aligned.shape[1] <= 0):\n",
        "                print(\"Failed to generate image\")\n",
        "              else:\n",
        "                face.image = cv2.resize(aligned, (size, size))\n",
        "                faces.append(face)\n",
        "              # sort the faces by area.\n",
        "              faces.sort(key=lambda x: x.area, reverse=True)\n",
        "              return len(face_results.detections), faces, \"Success\"\n"
      ],
      "metadata": {
        "id": "ZUcXJDsA9GrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MAIN FUNCTION**"
      ],
      "metadata": {
        "id": "kkoMzwvaCXMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  facetool = FaceTool(debug=False)\n",
        "  videoMode = True\n",
        "  path = \"samples\"\n",
        "  if videoMode:\n",
        "    vid = cv2.VideoCapture(0)\n",
        "    while True:\n",
        "      ret, image = vid.read()\n",
        "      face_count, faces, message = facetool.crop_and_align(image,zoom_factor=2, offset_y=-10)\n",
        "      if face_count > 0:\n",
        "        cv2.imwrite(path + \"/output/video.png\", faces[0].image)\n",
        "        cv2.imshow(\"aligned_image\", faces[0].image)\n",
        "      else:\n",
        "        print(message)\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "          break\n",
        "    vid.release()\n",
        "  else:\n",
        "    # path = os.path.dirname(os.path.abspath(__file__)) + \"/datasets/facetool\"\n",
        "    onlyfiles = [(f, join(path, f)) for f in listdir(path) if not f.startswith('.') and isfile(join(path, f))]\n",
        "    total = len(onlyfiles)\n",
        "    counter = 0\n",
        "    for filePath in onlyfiles:\n",
        "      print(filePath[1])\n",
        "      image = cv2.imread(filePath[1])\n",
        "      face_count, faces, message = facetool.crop_and_align(image, size=512, zoom_factor=2, offset_y=-10)\n",
        "      if face_count > 0:\n",
        "        cv2.imwrite(path + \"/output/\" + filePath[0], faces[0].image)\n",
        "        cv2.imshow(\"aligned_image\", faces[0].image)\n",
        "      else:\n",
        "        print(message)\n",
        "        key = cv2.waitKey(1000) & 0xFFa\n",
        "        if key == ord(\"q\"):\n",
        "                break\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "XwD6NWBUCjnd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}